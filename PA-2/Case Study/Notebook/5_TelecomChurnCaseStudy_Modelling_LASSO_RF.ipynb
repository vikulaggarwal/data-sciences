{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Telecom Churn Case Study</font>\n",
    "* Institution: IIIT, Bangalore and UpGrad\n",
    "* Course: PG Diploma in Machine Lerning and AI March 2018\n",
    "* Date: 14-Aug-2018\n",
    "* Submitted by:\n",
    "    1. Pandinath Siddineni (ID- APFE187000194)\n",
    "    2. AKNR Chandra Sekhar (ID- APFE187000315)\n",
    "    3. Brajesh Kumar       (ID- APFE187000149)\n",
    "    4. Shweta Tiwari\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>PART 3: LASSO & RANDOM FOREST</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>fb7_1.0</th>\n",
       "      <th>fb8_0.0</th>\n",
       "      <th>fb8_1.0</th>\n",
       "      <th>total_rech_data_amt_6</th>\n",
       "      <th>total_rech_data_amt_7</th>\n",
       "      <th>total_rech_data_amt_8</th>\n",
       "      <th>churn</th>\n",
       "      <th>rech_days_left_6</th>\n",
       "      <th>rech_days_left_7</th>\n",
       "      <th>rech_days_left_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000701601</td>\n",
       "      <td>1069.18</td>\n",
       "      <td>1349.85</td>\n",
       "      <td>3171.48</td>\n",
       "      <td>57.84</td>\n",
       "      <td>54.68</td>\n",
       "      <td>52.29</td>\n",
       "      <td>453.43</td>\n",
       "      <td>567.16</td>\n",
       "      <td>325.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001524846</td>\n",
       "      <td>378.72</td>\n",
       "      <td>492.22</td>\n",
       "      <td>137.36</td>\n",
       "      <td>413.69</td>\n",
       "      <td>351.03</td>\n",
       "      <td>35.08</td>\n",
       "      <td>94.66</td>\n",
       "      <td>80.63</td>\n",
       "      <td>136.48</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>354.00</td>\n",
       "      <td>207.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7002124215</td>\n",
       "      <td>514.45</td>\n",
       "      <td>597.75</td>\n",
       "      <td>637.76</td>\n",
       "      <td>102.41</td>\n",
       "      <td>132.11</td>\n",
       "      <td>85.14</td>\n",
       "      <td>757.93</td>\n",
       "      <td>896.68</td>\n",
       "      <td>983.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000887461</td>\n",
       "      <td>74.35</td>\n",
       "      <td>193.90</td>\n",
       "      <td>366.97</td>\n",
       "      <td>48.96</td>\n",
       "      <td>50.66</td>\n",
       "      <td>33.58</td>\n",
       "      <td>85.41</td>\n",
       "      <td>89.36</td>\n",
       "      <td>205.89</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>712.00</td>\n",
       "      <td>540.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000149764</td>\n",
       "      <td>977.02</td>\n",
       "      <td>2362.83</td>\n",
       "      <td>409.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5285.00</td>\n",
       "      <td>20424.00</td>\n",
       "      <td>455.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  arpu_6  arpu_7  arpu_8  onnet_mou_6  onnet_mou_7  \\\n",
       "0     7000701601 1069.18 1349.85 3171.48        57.84        54.68   \n",
       "1     7001524846  378.72  492.22  137.36       413.69       351.03   \n",
       "2     7002124215  514.45  597.75  637.76       102.41       132.11   \n",
       "3     7000887461   74.35  193.90  366.97        48.96        50.66   \n",
       "4     7000149764  977.02 2362.83  409.23         0.00         0.00   \n",
       "\n",
       "   onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8        ...         \\\n",
       "0        52.29        453.43        567.16        325.91        ...          \n",
       "1        35.08         94.66         80.63        136.48        ...          \n",
       "2        85.14        757.93        896.68        983.39        ...          \n",
       "3        33.58         85.41         89.36        205.89        ...          \n",
       "4         0.00          0.00          0.00          0.00        ...          \n",
       "\n",
       "   fb7_1.0  fb8_0.0  fb8_1.0  total_rech_data_amt_6  total_rech_data_amt_7  \\\n",
       "0        0        0        0                   0.00                   0.00   \n",
       "1        1        0        1                   0.00                 354.00   \n",
       "2        0        0        0                   0.00                   0.00   \n",
       "3        1        0        1                   0.00                 712.00   \n",
       "4        1        0        1                5285.00               20424.00   \n",
       "\n",
       "   total_rech_data_amt_8  churn  rech_days_left_6  rech_days_left_7  \\\n",
       "0                   0.00      1              3.00              6.00   \n",
       "1                 207.00      0              5.00              0.00   \n",
       "2                   0.00      0              0.00              0.00   \n",
       "3                 540.00      0             12.00             24.00   \n",
       "4                 455.00      0              0.00              1.00   \n",
       "\n",
       "   rech_days_left_8  \n",
       "0              5.00  \n",
       "1              1.00  \n",
       "2              0.00  \n",
       "3              7.00  \n",
       "4              5.00  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load clean telecom data file\n",
    "master_df = pd.read_csv('telecom_churn_data_clean.csv', low_memory=False)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (28504, 144)\n",
      "Dataframe Info: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28504 entries, 0 to 28503\n",
      "Columns: 144 entries, mobile_number to rech_days_left_8\n",
      "dtypes: float64(105), int64(39)\n",
      "memory usage: 31.3 MB\n"
     ]
    }
   ],
   "source": [
    "print('Dataframe Shape: ', master_df.shape)\n",
    "print(\"Dataframe Info: \\n\"); master_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop MemberID/Phone-number\n",
    "telecom = master_df.drop(['mobile_number'], axis=1)\n",
    "\n",
    "# Create X (independent variable) & y (dependent variable) \n",
    "df_telecom = telecom.drop(['churn'], axis=1)\n",
    "X = telecom.drop(['churn'], axis=1)\n",
    "y = telecom['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28504, 142)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Standardization/Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split in train & Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, train_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Dataframe Shape (19952, 142)\n",
      "X_test Dataframe Shape (8552, 142)\n",
      "Imbalance in Train Data: 0.05941698083151914\n",
      "Imbalance in Test Data: 0.059071207430340555\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Dataframe Shape {}\".format(X_train.shape))\n",
    "print(\"X_test Dataframe Shape {}\".format(X_test.shape))\n",
    "\n",
    "y_train_imb = (y_train != 0).sum()/(y_train == 0).sum()\n",
    "y_test_imb = (y_test != 0).sum()/(y_test == 0).sum()\n",
    "print(\"Imbalance in Train Data: {}\".format(y_train_imb))\n",
    "print(\"Imbalance in Test Data: {}\".format(y_test_imb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance data set by oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Training) Balance Data-Set --- SMOT\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(kind = \"regular\")\n",
    "X_tr,y_tr = sm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr Dataframe Shape (37666, 142)\n",
      "y_tr Dataframe Shape (37666,)\n",
      "Imbalance in Train Data: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"X_tr Dataframe Shape {}\".format(X_tr.shape))\n",
    "print(\"y_tr Dataframe Shape {}\".format(y_tr.shape))\n",
    "\n",
    "data_imbalance = (y_tr != 0).sum()/(y_tr == 0).sum()\n",
    "print(\"Imbalance in Train Data: {}\".format(data_imbalance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature reduction using LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37666, 43)\n",
      "[  0   1   3  10  13  14  20  23  29  34  39  40  47  49  52  53  58  65\n",
      "  78  79  80  83  91  92 101 102 104 107 108 109 110 111 113 116 118 120\n",
      " 121 125 132 135 139 140 141]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkumar5\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    " \n",
    "lsvc = LinearSVC(C=0.001, penalty=\"l1\", dual=False).fit(X_tr, y_tr)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_lasso = model.transform(X_tr)\n",
    "pos = model.get_support(indices=True)\n",
    " ### Feature reduction using RFE\n",
    "print(X_lasso.shape)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features identified by LASSO for model buidling:  ['arpu_6', 'arpu_7', 'onnet_mou_6', 'roam_ic_mou_7', 'roam_og_mou_7', 'roam_og_mou_8', 'loc_og_t2m_mou_8', 'loc_og_t2f_mou_8', 'loc_og_mou_8', 'std_og_t2m_mou_7', 'std_og_mou_6', 'std_og_mou_7', 'spl_og_mou_8', 'og_others_7', 'total_og_mou_7', 'total_og_mou_8', 'loc_ic_t2m_mou_7', 'loc_ic_mou_8', 'total_ic_mou_6', 'total_ic_mou_7', 'total_ic_mou_8', 'spl_ic_mou_8', 'total_rech_num_7', 'total_rech_num_8', 'last_day_rch_amt_8', 'vol_2g_mb_6', 'vol_2g_mb_8', 'vol_3g_mb_8', 'monthly_2g_6', 'monthly_2g_7', 'monthly_2g_8', 'sachet_2g_6', 'sachet_2g_8', 'monthly_3g_8', 'sachet_3g_7', 'aon', 'aug_vbc_3g', 'night6_1.0', 'fb7_0.0', 'fb8_1.0', 'rech_days_left_6', 'rech_days_left_7', 'rech_days_left_8']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#feature vector for decision tree#feature \n",
    "lasso_features = list(df_telecom.columns[pos])\n",
    "print(\"Features identified by LASSO for model buidling: \", lasso_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_lasso\n",
    "y_train = y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature space holds 37666 observations and 43 features\n",
      "Unique target labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print (\"Feature space holds %d observations and %d features\" % X_train.shape)\n",
    "print (\"Unique target labels:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with default hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bkumar5\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Importing random forest classifier from sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Running the random forest with default parameters.\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "X_test = pd.DataFrame(data=X_test).iloc[:, pos]\n",
    "\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      8075\n",
      "          1       0.48      0.49      0.48       477\n",
      "\n",
      "avg / total       0.94      0.94      0.94      8552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "# Let's check the report of our default model\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7825  250]\n",
      " [ 245  232]]\n"
     ]
    }
   ],
   "source": [
    "# Printing confusion matrix\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9421188026192704\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "NOTE: Hyperparameter Tunning is commented as it takes heavy computing power and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # GridSearchCV to find optimal n_estimators\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 5\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'max_depth': range(2, 20, 5)}\n",
    "\n",
    "# # instantiate the model\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# # fit tree on training data\n",
    "# rf = GridSearchCV(rf, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"accuracy\")\n",
    "# rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # scores of GridSearch CV\n",
    "# scores = rf.cv_results_\n",
    "# pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # plotting accuracies with max_depth\n",
    "# plt.figure()\n",
    "# plt.plot(scores[\"param_max_depth\"], \n",
    "#          scores[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(scores[\"param_max_depth\"], \n",
    "#          scores[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"max_depth\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # GridSearchCV to find optimal n_estimators\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 5\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'n_estimators': range(100, 1500, 400)}\n",
    "\n",
    "# # instantiate the model (note we are specifying a max_depth)\n",
    "# rf = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "\n",
    "# # fit tree on training data\n",
    "# rf = GridSearchCV(rf, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"accuracy\")\n",
    "# rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # scores of GridSearch CV\n",
    "# scores = rf.cv_results_\n",
    "# pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # plotting accuracies with n_estimators\n",
    "# plt.figure()\n",
    "# plt.plot(scores[\"param_n_estimators\"], \n",
    "#          scores[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(scores[\"param_n_estimators\"], \n",
    "#          scores[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"n_estimators\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # GridSearchCV to find optimal max_features\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 5\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'max_features': [4, 8, 14, 20, 24,28,32,36,40,44,48,52,56]}\n",
    "\n",
    "# # instantiate the model\n",
    "# rf = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "\n",
    "# # fit tree on training data\n",
    "# rf = GridSearchCV(rf, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"accuracy\")\n",
    "# rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # scores of GridSearch CV\n",
    "# scores = rf.cv_results_\n",
    "# pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # plotting accuracies with max_features\n",
    "# plt.figure()\n",
    "# plt.plot(scores[\"param_max_features\"], \n",
    "#          scores[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(scores[\"param_max_features\"], \n",
    "#          scores[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"max_features\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # GridSearchCV to find optimal min_samples_leaf\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 5\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "\n",
    "# # instantiate the model\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# # fit tree on training data\n",
    "# rf = GridSearchCV(rf, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"accuracy\")\n",
    "# rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # scores of GridSearch CV\n",
    "# scores = rf.cv_results_\n",
    "# pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # plotting accuracies with min_samples_leaf\n",
    "# plt.figure()\n",
    "# plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "#          scores[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "#          scores[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"min_samples_leaf\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # GridSearchCV to find optimal min_samples_split\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 5\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'min_samples_split': range(200, 500, 50)}\n",
    "\n",
    "# # instantiate the model\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# # fit tree on training data\n",
    "# rf = GridSearchCV(rf, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"accuracy\")\n",
    "# rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # scores of GridSearch CV\n",
    "# scores = rf.cv_results_\n",
    "# pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # plotting accuracies with min_samples_split\n",
    "# plt.figure()\n",
    "# plt.plot(scores[\"param_min_samples_split\"], \n",
    "#          scores[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(scores[\"param_min_samples_split\"], \n",
    "#          scores[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"min_samples_split\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search to Find Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create the parameter grid based on the results of random search \n",
    "# param_grid = {\n",
    "#     'max_depth': [4,8,10],\n",
    "#     'min_samples_leaf': range(100, 400, 200),\n",
    "#     'min_samples_split': range(200, 500, 200),\n",
    "#     'n_estimators': [100,200, 300], \n",
    "#     'max_features': [5, 10,20,30,40,50]\n",
    "# }\n",
    "# # Create a based model\n",
    "# rf = RandomForestClassifier()\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "#                           cv = 3, n_jobs = -1,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # printing the optimal accuracy score and hyperparameters\n",
    "# print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # model with the best hyperparameters\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rfc = RandomForestClassifier(bootstrap=True,\n",
    "#                              max_depth=10,\n",
    "#                              min_samples_leaf=100, \n",
    "#                              min_samples_split=200,\n",
    "#                              max_features=10,\n",
    "#                              n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # fit\n",
    "# rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # predict\n",
    "# predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # evaluation metrics\n",
    "# from sklearn.metrics import classification_report,confusion_matrix\n",
    "# print(classification_report(y_test,predictions))\n",
    "# print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>SUMMARY PART 3: LASSO & RANDOM FOREST</font>\n",
    "OBSERVATIONS\n",
    "1. Getting 94.0% accuracy \n",
    "2. Confusion matix clearly improved a lot, false positives still exist but reduced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
